{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch Version 확인\n",
    "import torch\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch Tensor Data Types (dtype)\n",
    "\n",
    "| <div align=\"center\">Data Type</div> | <div align=\"center\">dtype</div> | <div align=\"center\">CPU Tensor (Default)</div> | <div align=\"center\">GPU Tensor</div> |\n",
    "|-------------------------------------|------------------------------------------------------|-------------------------|---------------------------|\n",
    "|8-bit Integer (정수형)                 |`torch.int8`                                          |`torch.CharTensor`       |`torch.cuda.CharTensor`    |\n",
    "|8-bit Integer (정수형) (unsigned)      |`torch.uint8`                                         |`torch.ByteTensor`       |`torch.cuda.ByteTensor`    |\n",
    "|16-bit Integer (정수형)                |`torch.int16` or `torch.short`                        |`torch.ShortTensor`      |`torch.cuda.ShortTensor`   |\n",
    "|32-bit Integer (정수형)                |`torch.int32` or `torch.int`                          |`torch.IntTensor`        |`torch.cuda.IntTensor`     |\n",
    "|64-bit Integer (정수형)                |***Default(Integer)***, `torch.int64` or `torch.long` |`torch.LongTensor`       |`torch.cuda.LongTensor`    |\n",
    "|16-bit Floating Points (부동 소수점형)   |`torch.float16` or `torch.half`                       |`torch.HalfTensor`       |`torch.cuda.HalfTensor`    |\n",
    "|32-bit Floating Points (부동 소수점형)   |***Default***, `torch.float32` or `torch.float`       |`torch.FloatTensor`      |`torch.cuda.FloatTensor`   |\n",
    "|64-bit Floating Points (부동 소수점형)   |`torch.float64` or `torch.double`                     |`torch.DoubleTensor`     |`torch.cuda.DoubleTensor`  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 초기화 되지 않은 Tensor\n",
    "x = torch.empty(4, 2)\n",
    "print('torch.empty(4, 2)')\n",
    "print(x, end='\\n\\n')\n",
    "\n",
    "# 무작위로 초기화된 Tensor\n",
    "x = torch.rand(4, 2)\n",
    "print('torch.rand(4, 2)')\n",
    "print(x, end='\\n\\n')\n",
    "\n",
    "# Data type이 long이고, 0으로 채워진 Tensor\n",
    "x = torch.zeros(4, 2, dtype=torch.long)\n",
    "print('torch.zeros(4, 2, dtype=torch.long)')\n",
    "print(x, end='\\n\\n')\n",
    "\n",
    "# 2x4 크기, double type, 1로 채워진 Tensor\n",
    "x = torch.ones(2, 4, dtype=torch.double)\n",
    "print('torch.ones(2, 4, dtype=torch.double)')\n",
    "print(x, end='\\n\\n')\n",
    "\n",
    "# 사용자가 입력한 값으로 Tensor 초기화\n",
    "my_tensor = torch.tensor([3, 2.3])\n",
    "print('torch.tensor([3, 2.3]')\n",
    "print(my_tensor, end='\\n\\n')\n",
    "\n",
    "# (new_) 기존 Tensor의 dtype 및 device 속성을 유지한 채 새로운 Tensor를 생성\n",
    "x = my_tensor.new_zeros(3, 3)\n",
    "print('my_tensor.new_zeros(3, 3)')\n",
    "print(x, end='\\n\\n')\n",
    "\n",
    "x = my_tensor.new_ones(3, 3)\n",
    "print('my_tensor.new_ones(3, 3)')\n",
    "print(x, end='\\n\\n')\n",
    "\n",
    "# (_like) 기존 Tensor의 shape은 유지한 채 새로운 Tensor를 생성\n",
    "x = torch.randn_like(my_tensor, dtype=torch.double)\n",
    "print('torch.randn_like(my_tensor, dtype=torch.double)')\n",
    "print(x, end='\\n\\n')\n",
    "\n",
    "x = torch.zeros_like(my_tensor, dtype=torch.long)\n",
    "print('torch.zeros_like(my_tensor, dtype=torch.long)')\n",
    "print(x, end='\\n\\n')\n",
    "\n",
    "# Tensor의 shape 확인\n",
    "x = torch.rand(5, 2, 3)\n",
    "print(x.size())\n",
    "print(list(x.size()))\n",
    "\n",
    "# Tensor의 dtype 확인\n",
    "print(x.dtype)\n",
    "\n",
    "# Tensor의 device 확인\n",
    "print(x.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft = torch.IntTensor([1, 2, 3])\n",
    "print(ft)\n",
    "print(ft.dtype)\n",
    "\n",
    "# Tensor의 Type 변경\n",
    "print(ft.short())\n",
    "converted_ft = ft.to(dtype=torch.short)\n",
    "print(converted_ft)\n",
    "converted_ft = ft.type(torch.short)\n",
    "print(converted_ft)\n",
    "\n",
    "print(ft.long())\n",
    "converted_ft = ft.to(torch.long)\n",
    "print(converted_ft)\n",
    "converted_ft = ft.type(torch.long)\n",
    "print(converted_ft)\n",
    "\n",
    "print(ft.half())\n",
    "converted_ft = ft.to(torch.half)\n",
    "print(converted_ft)\n",
    "converted_ft = ft.type(torch.half)\n",
    "print(converted_ft)\n",
    "\n",
    "print(ft.float())\n",
    "converted_ft = ft.to(torch.float)\n",
    "print(converted_ft)\n",
    "converted_ft = ft.type(torch.float)\n",
    "print(converted_ft)\n",
    "\n",
    "print(ft.double())\n",
    "converted_ft = ft.to(torch.double)\n",
    "print(converted_ft)\n",
    "converted_ft = ft.type(torch.double)\n",
    "print(converted_ft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU Tensor (CUDA, MPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Windows 및 Linux 환경에서 CUDA 사용 가능 여부 확인\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # CUDA가 사용 가능하면 CUDA를 사용하여 GPU 가속, 그렇지 않으면 CPU를 사용\n",
    "print(device)\n",
    "\n",
    "# Mac 환경에서 MPS 사용 가능 여부 확인\n",
    "print(torch.backends.mps.is_built()) # PyTorch의 MPS 지원 여부\n",
    "print(torch.backends.mps.is_available()) # Mac의 MPS 지원 여부\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu') # MPS가 사용 가능하면 MPS를 사용하여 GPU 가속, 그렇지 않으면 CPU를 사용\n",
    "print(device)\n",
    "\n",
    "x = torch.randn(1, device='cpu') # CPU에 Tensor를 생성\n",
    "print(x)\n",
    "print(x.item())\n",
    "print(x.dtype)\n",
    "print(f'x.device : {x.device}')\n",
    "\n",
    "y = torch.ones_like(x, device=device) # GPU에 Tensor를 생성\n",
    "print(f'y.device : {y.device}')\n",
    "\n",
    "x = x.to(device=device) # CPU Tensor를 GPU Tensor로 이동\n",
    "print(f'x.device : {x.device}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
