{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch Version 확인\n",
    "import torch\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch Tensor Data Types (dtype)\n",
    "\n",
    "| <div align=\"center\">Data type</div> | <div align=\"center\">dtype</div> | <div align=\"center\">CPU tensor</div> | <div align=\"center\">GPU tensor</div> |\n",
    "|-------------------------------------|-----------------------------------------------------------------|-------------------------|---------------------------|\n",
    "|8-bit Integer (정수형)                 |`torch.int8`                                                     |`torch.CharTensor`       |`torch.cuda.CharTensor`    |\n",
    "|8-bit Integer (정수형) (unsigned)      |`torch.uint8`                                                    |`torch.ByteTensor`       |`torch.cuda.ByteTensor`    |\n",
    "|16-bit Integer (정수형)                |`torch.int16` or `torch.short`                                   |`torch.ShortTensor`      |`torch.cuda.ShortTensor`   |\n",
    "|32-bit Integer (정수형)                |`torch.int32` or `torch.int`                                     |`torch.IntTensor`        |`torch.cuda.IntTensor`     |\n",
    "|64-bit Integer (정수형)                |***Default(Integer)***, `torch.int64` or `torch.long`            |`torch.LongTensor`       |`torch.cuda.LongTensor`    |\n",
    "|16-bit Floating Points (부동 소수점형)   |`torch.float16` or `torch.half`                                  |`torch.HalfTensor`       |`torch.cuda.HalfTensor`    |\n",
    "|32-bit Floating Points (부동 소수점형)   |***Default(Floating Points)***, `torch.float32` or `torch.float` |`torch.FloatTensor`      |`torch.cuda.FloatTensor`   |\n",
    "|64-bit Floating Points (부동 소수점형)   |`torch.float64` or `torch.double`                                |`torch.DoubleTensor`     |`torch.cuda.DoubleTensor`  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 초기화 되지 않은 Tensor\n",
    "x = torch.empty(4, 2)\n",
    "print('torch.empty(4, 2)')\n",
    "print(x, end='\\n\\n')\n",
    "\n",
    "# 무작위로 초기화된 Tensor\n",
    "x = torch.rand(4, 2)\n",
    "print('torch.rand(4, 2)')\n",
    "print(x, end='\\n\\n')\n",
    "\n",
    "# Data type이 long이고, 0으로 채워진 Tensor\n",
    "x = torch.zeros(4, 2, dtype=torch.long)\n",
    "print('torch.zeros(4, 2, dtype=torch.long)')\n",
    "print(x, end='\\n\\n')\n",
    "\n",
    "# 2x4 크기, double type, 1로 채워진 Tensor\n",
    "x = torch.ones(2, 4, dtype=torch.double)\n",
    "print('torch.ones(2, 4, dtype=torch.double)')\n",
    "print(x, end='\\n\\n')\n",
    "\n",
    "# 사용자가 입력한 값으로 Tensor 초기화\n",
    "my_tensor = torch.tensor([3, 2.3])\n",
    "print('torch.tensor([3, 2.3]')\n",
    "print(my_tensor, end='\\n\\n')\n",
    "\n",
    "# (new_) 기존 Tensor의 dtype 및 device 속성을 유지한 채 새로운 Tensor를 생성\n",
    "x = my_tensor.new_zeros(3, 3)\n",
    "print('my_tensor.new_zeros(3, 3)')\n",
    "print(x, end='\\n\\n')\n",
    "\n",
    "x = my_tensor.new_ones(3, 3)\n",
    "print('my_tensor.new_ones(3, 3)')\n",
    "print(x, end='\\n\\n')\n",
    "\n",
    "# (_like) 기존 Tensor의 shape은 유지한 채 새로운 Tensor를 생성\n",
    "x = torch.randn_like(my_tensor, dtype=torch.double)\n",
    "print('torch.randn_like(my_tensor, dtype=torch.double)')\n",
    "print(x, end='\\n\\n')\n",
    "\n",
    "x = torch.zeros_like(my_tensor, dtype=torch.long)\n",
    "print('torch.zeros_like(my_tensor, dtype=torch.long)')\n",
    "print(x, end='\\n\\n')\n",
    "\n",
    "# Tensor의 shape 확인\n",
    "x = torch.rand(5, 2, 3)\n",
    "print(x.size())\n",
    "print(list(x.size()))\n",
    "\n",
    "# Tensor의 dtype 확인\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3], dtype=torch.int32)\n",
      "torch.int32\n",
      "tensor([1, 2, 3], dtype=torch.int16)\n",
      "tensor([1, 2, 3])\n",
      "tensor([1., 2., 3.], dtype=torch.float16)\n",
      "tensor([1., 2., 3.])\n",
      "tensor([1., 2., 3.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "ft = torch.IntTensor([1, 2, 3])\n",
    "print(ft)\n",
    "print(ft.dtype)\n",
    "\n",
    "# Tensor의 Type 변경\n",
    "print(ft.short())\n",
    "print(ft.long())\n",
    "print(ft.half())\n",
    "print(ft.float())\n",
    "print(ft.double())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CUDA Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
