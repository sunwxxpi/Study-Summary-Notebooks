{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch Version 확인\n",
    "import torch\n",
    "\n",
    "print(torch.__version__)\n",
    "\n",
    "# Tensor의 shape 확인\n",
    "x = torch.rand(5, 2, 3)\n",
    "print(x.shape)\n",
    "print(list(x.shape))\n",
    "print(x.size())\n",
    "print(list(x.size()))\n",
    "print(x.size(1))\n",
    "\n",
    "# Tensor의 dimension 확인\n",
    "print(x.ndim)\n",
    "print(x.dim())\n",
    "\n",
    "# Tensor의 dtype 확인\n",
    "print(x.dtype)\n",
    "\n",
    "# Tensor의 device 확인\n",
    "print(x.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch Tensor Data Types (dtype)\n",
    "\n",
    "| <div align=\"center\">Data Type</div> | <div align=\"center\">dtype</div> | <div align=\"center\">CPU Tensor (Default)</div> | <div align=\"center\">GPU Tensor</div> |\n",
    "|-------------------------------------|------------------------------------------------------|-------------------------|---------------------------|\n",
    "|8-bit Integer (정수형)                 |`torch.int8`                                          |`torch.CharTensor`       |`torch.cuda.CharTensor`    |\n",
    "|8-bit Integer (정수형) (unsigned)      |`torch.uint8`                                         |`torch.ByteTensor`       |`torch.cuda.ByteTensor`    |\n",
    "|16-bit Integer (정수형)                |`torch.int16` or `torch.short`                        |`torch.ShortTensor`      |`torch.cuda.ShortTensor`   |\n",
    "|32-bit Integer (정수형)                |`torch.int32` or `torch.int`                          |`torch.IntTensor`        |`torch.cuda.IntTensor`     |\n",
    "|64-bit Integer (정수형)                |***Default(Integer)***, `torch.int64` or `torch.long` |`torch.LongTensor`       |`torch.cuda.LongTensor`    |\n",
    "|16-bit Floating Points (부동 소수점형)   |`torch.float16` or `torch.half`                       |`torch.HalfTensor`       |`torch.cuda.HalfTensor`    |\n",
    "|32-bit Floating Points (부동 소수점형)   |***Default***, `torch.float32` or `torch.float`       |`torch.FloatTensor`      |`torch.cuda.FloatTensor`   |\n",
    "|64-bit Floating Points (부동 소수점형)   |`torch.float64` or `torch.double`                     |`torch.DoubleTensor`     |`torch.cuda.DoubleTensor`  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 초기화 되지 않은 Tensor\n",
    "x = torch.empty(4, 2)\n",
    "print('torch.empty(4, 2)')\n",
    "print(x, end='\\n\\n')\n",
    "\n",
    "# 무작위로 초기화된 Tensor\n",
    "x = torch.rand(4, 2)\n",
    "print('torch.rand(4, 2)')\n",
    "print(x, end='\\n\\n')\n",
    "\n",
    "# Data type이 long이고, 0으로 채워진 Tensor\n",
    "x = torch.zeros(4, 2, dtype=torch.long)\n",
    "print('torch.zeros(4, 2, dtype=torch.long)')\n",
    "print(x, end='\\n\\n')\n",
    "\n",
    "# 2x4 크기, double type, 1로 채워진 Tensor\n",
    "x = torch.ones(2, 4, dtype=torch.double)\n",
    "print('torch.ones(2, 4, dtype=torch.double)')\n",
    "print(x, end='\\n\\n')\n",
    "\n",
    "# 사용자가 입력한 값으로 Tensor 초기화\n",
    "my_tensor = torch.tensor([3, 2.3])\n",
    "print('torch.tensor([3, 2.3]')\n",
    "print(my_tensor, end='\\n\\n')\n",
    "\n",
    "# (new_) 기존 Tensor의 dtype 및 device 속성을 유지한 채 새로운 Tensor를 생성\n",
    "x = my_tensor.new_zeros(3, 3)\n",
    "print('my_tensor.new_zeros(3, 3)')\n",
    "print(x, end='\\n\\n')\n",
    "\n",
    "x = my_tensor.new_ones(3, 3)\n",
    "print('my_tensor.new_ones(3, 3)')\n",
    "print(x, end='\\n\\n')\n",
    "\n",
    "# (_like) 기존 Tensor의 shape은 유지한 채 새로운 Tensor를 생성\n",
    "x = torch.randn_like(my_tensor, dtype=torch.double)\n",
    "print('torch.randn_like(my_tensor, dtype=torch.double)')\n",
    "print(x, end='\\n\\n')\n",
    "\n",
    "x = torch.zeros_like(my_tensor, dtype=torch.long)\n",
    "print('torch.zeros_like(my_tensor, dtype=torch.long)')\n",
    "print(x, end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft = torch.IntTensor([1, 2, 3])\n",
    "print(ft)\n",
    "print(ft.dtype)\n",
    "\n",
    "# Tensor의 Type 변경\n",
    "print(ft.short())\n",
    "converted_ft = ft.to(dtype=torch.short)\n",
    "print(converted_ft)\n",
    "converted_ft = ft.type(torch.short)\n",
    "print(converted_ft)\n",
    "\n",
    "print(ft.long())\n",
    "converted_ft = ft.to(torch.long)\n",
    "print(converted_ft)\n",
    "converted_ft = ft.type(torch.long)\n",
    "print(converted_ft)\n",
    "\n",
    "print(ft.half())\n",
    "converted_ft = ft.to(torch.half)\n",
    "print(converted_ft)\n",
    "converted_ft = ft.type(torch.half)\n",
    "print(converted_ft)\n",
    "\n",
    "print(ft.float())\n",
    "converted_ft = ft.to(torch.float)\n",
    "print(converted_ft)\n",
    "converted_ft = ft.type(torch.float)\n",
    "print(converted_ft)\n",
    "\n",
    "print(ft.double())\n",
    "converted_ft = ft.to(torch.double)\n",
    "print(converted_ft)\n",
    "converted_ft = ft.type(torch.double)\n",
    "print(converted_ft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU Tensor (CUDA, MPS)\n",
    "- GPU 가속 Platform\n",
    "    - CUDA : **NVIDIA**에서 제공\n",
    "    - MPS : **Apple**에서 제공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Windows 및 Linux 환경에서 CUDA 사용 가능 여부 확인\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # CUDA가 사용 가능하면 CUDA를 사용하여 GPU 가속, 그렇지 않으면 CPU를 사용\n",
    "print(device)\n",
    "\n",
    "# Mac 환경에서 MPS 사용 가능 여부 확인\n",
    "print(torch.backends.mps.is_built()) # PyTorch Version의 MPS 지원 여부\n",
    "print(torch.backends.mps.is_available()) # Mac Hardware 및 Version의 MPS 지원 여부\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu') # MPS가 사용 가능하면 MPS를 사용하여 GPU 가속, 그렇지 않으면 CPU를 사용\n",
    "print(device)\n",
    "\n",
    "x = torch.randn(1) # CPU에 Tensor를 생성 (device='cpu', Default)\n",
    "print(x)\n",
    "print(x.item())\n",
    "print(x.dtype)\n",
    "print(f'x.device : {x.device}')\n",
    "\n",
    "# device에 [torch.device('cuda') or 'cuda'] 모두 할당 가능. (동일하게 동작)\n",
    "y = torch.ones_like(x, device=device) # GPU에 Tensor를 생성\n",
    "print(f'y.device : {y.device}', f'y.dtype : {y.dtype}')\n",
    "\n",
    "x = x.to(device=device, dtype=torch.float16) # CPU Tensor를 GPU Tensor로 이동, dtype을 변경\n",
    "print(f'x.device : {x.device}', f'x.dtype : {x.dtype}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다차원 Tensor\n",
    "\n",
    "- 0D Tensor (Scalar)\n",
    "    - 하나의 숫자를 담고 있는 Tensor\n",
    "    - 형상과 축이 없음.\n",
    "\n",
    "- 1D Tensor (Vector)\n",
    "    - 값들을 저장한 리스트와 유사한 Tensor\n",
    "    - 하나의 축이 존재\n",
    "\n",
    "- 2D Tensor (Matrix)\n",
    "    - 행렬과 같은 모양으로 두 개의 축이 존재\n",
    "    - 일반적인 수치, 통계 데이터셋 등이 존재\n",
    "    - 주로 Samples, Features를 가진 구조로 사용\n",
    "\n",
    "- 3D Tensor\n",
    "    - Cube와 같은 모양으로 세 개의 축이 존재\n",
    "    - 데이터가 연속된 시퀀스 데이터나 시간 축이 포함된 시계열 데이터에 해당\n",
    "    - 주식 가격 데이터셋, 시간에 따른 질병 발병 데이터셋 등이 존재\n",
    "    - 주로 Samples, Timesteps, Features를 가진 구조로 사용\n",
    "\n",
    "- 4D Tensor\n",
    "    - 4개의 축\n",
    "    - 컬러 이미지 데이터가 대표적인 사례 (흑백 이미지 데이터는 3D Tensor로 표현 가능)\n",
    "    - 주로 Samples, Color Channel, Height, Width를 가진 구조로 사용 \n",
    "    - `Tensor : (B, C, H, W)`\n",
    "\n",
    "- 5D Tensor\n",
    "    - 5개의 축\n",
    "    - 비디오 데이터가 대표적인 사례\n",
    "    - 주로 Samples, Frames, Color Channel, Height, Width를 가진 구조로 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0D Tensor (Scalar)\n",
    "print('0D Tensor (Scalar)')\n",
    "t0 = torch.tensor(0)\n",
    "print(t0.shape)\n",
    "print(t0.ndim)\n",
    "print(t0, end='\\n\\n')\n",
    "\n",
    "# 1D Tensor (Vector)\n",
    "print('1D Tensor (Vector)')\n",
    "t1 = torch.tensor([1, 2, 3])\n",
    "print(t1.shape)\n",
    "print(t1.ndim)\n",
    "print(t1, end='\\n\\n')\n",
    "\n",
    "# 2D Tensor (Matrix)\n",
    "print('2D Tensor (Matrix)')\n",
    "t2 = torch.tensor([[1, 2, 3], \n",
    "                   [4, 5, 6]])\n",
    "print(t2.shape)\n",
    "print(t2.ndim)\n",
    "print(t2, end='\\n\\n')\n",
    "\n",
    "# 3D Tensor\n",
    "print('3D Tensor')\n",
    "t3 = torch.tensor([[[1, 2, 3], \n",
    "                    [4, 5, 6]],\n",
    "                   [[7, 8, 9], \n",
    "                    [10, 11, 12]]])\n",
    "print(t3.shape)\n",
    "print(t3.ndim)\n",
    "print(t3, end='\\n\\n')\n",
    "\n",
    "# 4D Tensor\n",
    "print('4D Tensor')\n",
    "t4 = torch.tensor([[[[1, 2, 3], \n",
    "                     [4, 5, 6]],\n",
    "                    [[7, 8, 9], \n",
    "                     [10, 11, 12]]],\n",
    "                   [[[13, 14, 15], \n",
    "                     [16, 17, 18]],\n",
    "                    [[19, 20, 21], \n",
    "                     [22, 23, 24]]]])\n",
    "print(t4.shape)\n",
    "print(t4.ndim)\n",
    "print(t4, end='\\n\\n')\n",
    "\n",
    "# 5D Tensor\n",
    "print('5D Tensor')\n",
    "t5 = torch.tensor([[[[[1, 2, 3], \n",
    "                      [4, 5, 6]],\n",
    "                     [[7, 8, 9], \n",
    "                      [10, 11, 12]]],\n",
    "                    [[[13, 14, 15], \n",
    "                      [16, 17, 18]],\n",
    "                     [[19, 20, 21], \n",
    "                      [22, 23, 24]]]],\n",
    "                   [[[[25, 26, 27], \n",
    "                      [28, 29, 30]],\n",
    "                     [[31, 32, 33], \n",
    "                      [34, 35, 36]]],\n",
    "                    [[[37, 38, 39], \n",
    "                      [40, 41, 42]],\n",
    "                     [[43, 44, 45], \n",
    "                      [46, 47, 48]]]]])\n",
    "print(t5.shape)\n",
    "print(t5.ndim)\n",
    "print(t5, end='\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
