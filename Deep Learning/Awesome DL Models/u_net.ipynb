{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### U-Net Overview\n",
    "U-Net은 주로 의료 영상에서 사용되는 이미지 분할을 위한 Convolution Neural Network, 즉 CNNs입니다. U-Net의 주요 특징은 U자형의 대칭 구조로, 인코딩 경로와 디코딩 경로로 구성되어 있습니다. 인코딩 경로는 입력 이미지를 점점 더 작은 차원으로 축소하고, 디코딩 경로는 이를 다시 원래 크기로 확장하면서 정확한 예측을 만들어냅니다. 인코딩과 디코딩 경로 사이에는 skip connection이 있어, 인코딩 단계에서 추출된 특징을 디코딩 단계에서 다시 사용하여 더 좋은 결과를 얻을 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### U-Net Architecture\n",
    "\n",
    "- 인코딩 경로 (Contracting Path):\n",
    "    - 컨볼루션 레이어와 풀링 레이어를 사용하여 점진적으로 이미지의 차원을 줄입니다.\n",
    "- 디코딩 경로 (Expansive Path):\n",
    "    - 업샘플링과 컨볼루션 레이어를 사용하여 이미지의 차원을 원래 크기로 복원합니다.\n",
    "- Skip Connections:\n",
    "    - 인코딩 경로의 각 단계에서 얻은 특징 맵을 디코딩 경로의 대응하는 단계에 결합합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch Implementation\n",
    "\n",
    "```python\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms.functional import center_crop\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(UNet, self).__init__()\n",
    "        \n",
    "        # 인코딩 경로 (Contracting Path)\n",
    "        self.encoder1 = self.contracting_block(in_channels, 64)   # 첫 번째 인코딩 블록: in_channels -> 64 채널\n",
    "        self.encoder2 = self.contracting_block(64, 128)           # 두 번째 인코딩 블록: 64 -> 128 채널\n",
    "        self.encoder3 = self.contracting_block(128, 256)          # 세 번째 인코딩 블록: 128 -> 256 채널\n",
    "        self.encoder4 = self.contracting_block(256, 512)          # 네 번째 인코딩 블록: 256 -> 512 채널\n",
    "        \n",
    "        # 중심부 (Bottom of the U)\n",
    "        self.bottleneck = self.contracting_block(512, 1024)       # 중심부 블록: 512 -> 1024 채널\n",
    "        \n",
    "        # 업샘플링 레이어\n",
    "        self.upconv4 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)  # 업샘플링: 1024 -> 512 채널\n",
    "        self.upconv3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)   # 업샘플링: 512 -> 256 채널\n",
    "        self.upconv2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)   # 업샘플링: 256 -> 128 채널\n",
    "        self.upconv1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)    # 업샘플링: 128 -> 64 채널\n",
    "        \n",
    "        # 디코딩 경로 (Expansive Path)\n",
    "        self.decoder4 = self.expansive_block(1024, 512)           # 첫 번째 디코딩 블록: 1024 -> 512 채널\n",
    "        self.decoder3 = self.expansive_block(512, 256)            # 두 번째 디코딩 블록: 512 -> 256 채널\n",
    "        self.decoder2 = self.expansive_block(256, 128)            # 세 번째 디코딩 블록: 256 -> 128 채널\n",
    "        self.decoder1 = self.expansive_block(128, 64)             # 네 번째 디코딩 블록: 128 -> 64 채널\n",
    "        \n",
    "        # 마지막 출력 레이어\n",
    "        self.final_conv = nn.Conv2d(64, out_channels, kernel_size=1)  # 최종 출력 레이어: 64 -> out_channels\n",
    "        \n",
    "    def contracting_block(self, in_channels, out_channels):\n",
    "        \"\"\"\n",
    "        인코딩 블록 정의: Conv2d -> ReLU -> Conv2d -> ReLU\n",
    "        \"\"\"\n",
    "        block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        return block\n",
    "    \n",
    "    def expansive_block(self, in_channels, out_channels):\n",
    "        \"\"\"\n",
    "        디코딩 블록 정의: Conv2d -> ReLU -> Conv2d -> ReLU\n",
    "        \"\"\"\n",
    "        block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        return block\n",
    "    \n",
    "    def crop_and_concat(self, upsampled, bypass):\n",
    "        \"\"\"\n",
    "        크기를 맞추기 위해 센터 크롭을 적용하고, 인코딩 경로의 특징 맵과 업샘플링된 특징 맵을 결합\n",
    "        \"\"\"\n",
    "        _, _, H, W = upsampled.size()\n",
    "        bypass = center_crop(bypass, [H, W])  # 인코딩 경로의 특징 맵을 업샘플링된 맵의 크기에 맞게 Crop\n",
    "        \n",
    "        return torch.cat((bypass, upsampled), dim=1)  # 채널 방향으로 결합 (dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # 인코딩 경로 (Contracting Path)\n",
    "        enc1 = self.encoder1(x)                                          # 첫 번째 인코딩 블록\n",
    "        enc2 = self.encoder2(F.max_pool2d(enc1, kernel_size=2))          # 두 번째 인코딩 블록\n",
    "        enc3 = self.encoder3(F.max_pool2d(enc2, kernel_size=2))          # 세 번째 인코딩 블록\n",
    "        enc4 = self.encoder4(F.max_pool2d(enc3, kernel_size=2))          # 네 번째 인코딩 블록\n",
    "        \n",
    "        # 중심부 (Bottom of the U)\n",
    "        bottleneck = self.bottleneck(F.max_pool2d(enc4, kernel_size=2))  # 중심부 블록\n",
    "        \n",
    "        # 디코딩 경로 (Expansive Path)\n",
    "        up4 = self.upconv4(bottleneck)                                   # 업샘플링: 1024 -> 512 채널\n",
    "        merged4 = self.crop_and_concat(up4, enc4)                        # 인코딩 경로의 특징 맵과 결합\n",
    "        dec4 = self.decoder4(merged4)                                    # 디코딩 블록 적용\n",
    "        \n",
    "        up3 = self.upconv3(dec4)                                         # 업샘플링: 512 -> 256 채널\n",
    "        merged3 = self.crop_and_concat(up3, enc3)                        # 인코딩 경로의 특징 맵과 결합\n",
    "        dec3 = self.decoder3(merged3)                                    # 디코딩 블록 적용\n",
    "        \n",
    "        up2 = self.upconv2(dec3)                                         # 업샘플링: 256 -> 128 채널\n",
    "        merged2 = self.crop_and_concat(up2, enc2)                        # 인코딩 경로의 특징 맵과 결합\n",
    "        dec2 = self.decoder2(merged2)                                    # 디코딩 블록 적용\n",
    "        \n",
    "        up1 = self.upconv1(dec2)                                         # 업샘플링: 128 -> 64 채널\n",
    "        merged1 = self.crop_and_concat(up1, enc1)                        # 인코딩 경로의 특징 맵과 결합\n",
    "        dec1 = self.decoder1(merged1)                                    # 디코딩 블록 적용\n",
    "        \n",
    "        # 최종 출력 레이어\n",
    "        return self.final_conv(dec1)                                     # 최종 출력 레이어를 통해 결과 반환\n",
    "\n",
    "# 모델 사용 예시\n",
    "if __name__ == \"__main__\":\n",
    "    model = UNet(in_channels=1, out_channels=2)\n",
    "    input_tensor = torch.randn(16, 1, 572, 572)  # 입력 크기: (16, 1, 572, 572)\n",
    "    \n",
    "    # 모델 구조 요약\n",
    "    summary(model, input_size=input_tensor.shape, col_width=20, depth=5, row_settings=[\"depth\", \"var_names\"], col_names=[\"input_size\", \"kernel_size\", \"output_size\", \"params_percent\"])\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
