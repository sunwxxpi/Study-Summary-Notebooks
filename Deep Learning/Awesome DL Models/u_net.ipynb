{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### U-Net Overview\n",
    "U-Net은 주로 의료 영상에서 사용되는 이미지 분할을 위한 Convolution Neural Network, 즉 CNNs입니다. U-Net의 주요 특징은 U자형의 대칭 구조로, 인코딩 경로와 디코딩 경로로 구성되어 있습니다. 인코딩 경로는 입력 이미지를 점점 더 작은 차원으로 축소하고, 디코딩 경로는 이를 다시 원래 크기로 확장하면서 정확한 예측을 만들어냅니다. 인코딩과 디코딩 경로 사이에는 skip connection이 있어, 인코딩 단계에서 추출된 특징을 디코딩 단계에서 다시 사용하여 더 좋은 결과를 얻을 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### U-Net Architecture\n",
    "\n",
    "- 인코딩 경로 (Contracting Path):\n",
    "    - 컨볼루션 레이어와 풀링 레이어를 사용하여 점진적으로 이미지의 차원을 줄입니다.\n",
    "- 디코딩 경로 (Expansive Path):\n",
    "    - 업샘플링과 컨볼루션 레이어를 사용하여 이미지의 차원을 원래 크기로 복원합니다.\n",
    "- Skip Connections:\n",
    "    - 인코딩 경로의 각 단계에서 얻은 특징 맵을 디코딩 경로의 대응하는 단계에 결합합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch Implementation\n",
    "\n",
    "```python\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(UNet, self).__init__()\n",
    "        \n",
    "        # 인코딩 경로 (Contracting Path)\n",
    "        self.encoder1 = self.contracting_block(in_channels, 64)   # 첫 번째 인코딩 블록: in_channels -> 64 채널\n",
    "        self.encoder2 = self.contracting_block(64, 128)           # 두 번째 인코딩 블록: 64 -> 128 채널\n",
    "        self.encoder3 = self.contracting_block(128, 256)          # 세 번째 인코딩 블록: 128 -> 256 채널\n",
    "        self.encoder4 = self.contracting_block(256, 512)          # 네 번째 인코딩 블록: 256 -> 512 채널\n",
    "        \n",
    "        # 중심부 (Bottom of the U)\n",
    "        self.bottom = self.contracting_block(512, 1024)           # 중심부 블록: 512 -> 1024 채널\n",
    "        \n",
    "        # 디코딩 경로 (Expansive Path)\n",
    "        self.upconv4 = self.expansive_block(1024, 512)            # 첫 번째 디코딩 블록: 1024 -> 512 채널\n",
    "        self.upconv3 = self.expansive_block(512, 256)             # 두 번째 디코딩 블록: 512 -> 256 채널\n",
    "        self.upconv2 = self.expansive_block(256, 128)             # 세 번째 디코딩 블록: 256 -> 128 채널\n",
    "        self.upconv1 = self.expansive_block(128, 64)              # 네 번째 디코딩 블록: 128 -> 64 채널\n",
    "        \n",
    "        # 마지막 출력 레이어\n",
    "        self.final_conv = nn.Conv2d(64, out_channels, kernel_size=1) # 최종 출력 레이어: 1x1 컨볼루션, 64 -> out_channels\n",
    "    \n",
    "    def contracting_block(self, in_channels, out_channels):\n",
    "        \"\"\"\n",
    "        인코딩 블록 정의: Conv2d -> ReLU -> Conv2d -> ReLU\n",
    "        패딩 없이 각 컨볼루션을 적용하여 출력 크기 축소\n",
    "        \"\"\"\n",
    "        block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        return block\n",
    "    \n",
    "    def expansive_block(self, in_channels, out_channels):\n",
    "        \"\"\"\n",
    "        디코딩 블록 정의: ConvTranspose2d -> ReLU -> Conv2d -> ReLU -> Conv2d -> ReLU\n",
    "        ConvTranspose2d를 통해 업샘플링 및 출력 크기 증가\n",
    "        \"\"\"\n",
    "        block = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        return block\n",
    "    \n",
    "    def crop_and_concat(self, upsampled, bypass):\n",
    "        \"\"\"\n",
    "        크기를 맞추기 위해 센터 크롭을 적용하고, 업샘플된 텐서와 인코딩 블록 출력을 결합\n",
    "        \"\"\"\n",
    "        _, _, H, W = upsampled.size()\n",
    "        bypass = F.center_crop(bypass, [H, W])\n",
    "        return torch.cat((upsampled, bypass), dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # 인코딩 경로 (Contracting Path)\n",
    "        enc1 = self.encoder1(x)                                      # 첫 번째 인코딩 블록을 통해 특징 추출\n",
    "        enc2 = self.encoder2(F.max_pool2d(enc1, kernel_size=2))      # 두 번째 인코딩 블록: max pooling 후 특징 추출\n",
    "        enc3 = self.encoder3(F.max_pool2d(enc2, kernel_size=2))      # 세 번째 인코딩 블록: max pooling 후 특징 추출\n",
    "        enc4 = self.encoder4(F.max_pool2d(enc3, kernel_size=2))      # 네 번째 인코딩 블록: max pooling 후 특징 추출\n",
    "        \n",
    "        # 중심부 (Bottom of the U)\n",
    "        bottleneck = self.bottom(F.max_pool2d(enc4, kernel_size=2))  # 중심부 블록: max pooling 후 특징 추출\n",
    "        \n",
    "        # 디코딩 경로 (Expansive Path)\n",
    "        dec4 = self.crop_and_concat(self.upconv4(bottleneck), enc4)  # 첫 번째 디코딩 블록: 업샘플링 후 결합\n",
    "        dec3 = self.crop_and_concat(self.upconv3(dec4), enc3)        # 두 번째 디코딩 블록: 업샘플링 후 결합\n",
    "        dec2 = self.crop_and_concat(self.upconv2(dec3), enc2)        # 세 번째 디코딩 블록: 업샘플링 후 결합\n",
    "        dec1 = self.crop_and_concat(self.upconv1(dec2), enc1)        # 네 번째 디코딩 블록: 업샘플링 후 결합\n",
    "        \n",
    "        # 최종 출력 레이어\n",
    "        return self.final_conv(dec1)                                 # 최종 출력 레이어를 통해 결과 반환\n",
    "\n",
    "\n",
    "model = UNet(in_channels=3, out_channels=2)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
